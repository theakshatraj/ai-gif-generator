import { exec } from "child_process"
import path from "path"
import fs from "fs"
import { promisify } from "util"

const execAsync = promisify(exec)

class VideoAnalysisService {
  constructor() {
    this.ffmpegPath = "C:\\Program Files (x86)\\ffmpeg-2025-05-21-git-4099d53759-full_build\\bin\\ffmpeg.exe"
    this.tempDir = path.join(process.cwd(), "temp")
  }

  // Extract frames at regular intervals to analyze video content
  async extractFramesForAnalysis(videoPath, videoDuration) {
    try {
      console.log("üñºÔ∏è Extracting frames for video analysis...")

      const frameDir = path.join(this.tempDir, `frames_${Date.now()}`)
      if (!fs.existsSync(frameDir)) {
        fs.mkdirSync(frameDir, { recursive: true })
      }

      // Extract 1 frame every 2 seconds
      const frameInterval = 2
      const totalFrames = Math.floor(videoDuration / frameInterval)

      console.log(`üìä Extracting ${totalFrames} frames (1 every ${frameInterval}s)`)

      const command = `"${this.ffmpegPath}" -i "${videoPath}" -vf "fps=1/${frameInterval}" "${frameDir}/frame_%03d.jpg"`

      await execAsync(command, { timeout: 30000 })

      // Get list of extracted frames
      const frames = fs
        .readdirSync(frameDir)
        .filter((file) => file.endsWith(".jpg"))
        .sort()
        .map((file, index) => ({
          timestamp: index * frameInterval,
          path: path.join(frameDir, file),
          filename: file,
        }))

      console.log(`‚úÖ Extracted ${frames.length} frames for analysis`)
      return { frames, frameDir }
    } catch (error) {
      console.error("‚ùå Frame extraction failed:", error)
      throw error
    }
  }

  // Analyze video content using frame extraction and scene detection
  async analyzeVideoContent(videoPath, videoDuration, prompt) {
    try {
      console.log("üîç Analyzing video content...")

      // Extract frames for analysis
      const { frames, frameDir } = await this.extractFramesForAnalysis(videoPath, videoDuration)

      // Create a more detailed transcript based on frame analysis
      const segments = []

      // Divide video into segments based on extracted frames
      for (let i = 0; i < frames.length; i++) {
        const frame = frames[i]
        const nextFrame = frames[i + 1]

        const startTime = frame.timestamp
        const endTime = nextFrame ? nextFrame.timestamp : videoDuration

        // Create segment description based on position and prompt context
        const description = this.generateSegmentDescription(startTime, endTime, videoDuration, prompt)

        segments.push({
          start: startTime,
          end: Math.min(endTime, videoDuration),
          text: description,
        })
      }

      // Clean up frame directory
      this.cleanupFrames(frameDir)

      // Create enhanced transcript
      const transcript = {
        text: segments.map((seg) => seg.text).join(" "),
        segments: segments,
      }

      console.log("‚úÖ Video content analysis completed")
      console.log(`üìä Created ${segments.length} content-aware segments`)

      return transcript
    } catch (error) {
      console.error("‚ùå Video analysis failed:", error)
      // Fallback to basic analysis
      return this.createBasicAnalysis(videoDuration, prompt)
    }
  }

  generateSegmentDescription(startTime, endTime, totalDuration, prompt) {
    const position = startTime / totalDuration
    const duration = endTime - startTime

    // Analyze prompt for key terms
    const promptLower = prompt.toLowerCase()
    const isAction = /dance|dancing|move|moving|action|jump|run|walk/.test(promptLower)
    const isEmotion = /laugh|laughing|smile|smiling|cry|crying|happy|sad|angry|surprised/.test(promptLower)
    const isComedy = /funny|comedy|comedic|humor|joke|hilarious/.test(promptLower)
    const isHighlight = /highlight|best|good|great|amazing|awesome/.test(promptLower)

    let description = ""

    // Position-based descriptions
    if (position < 0.2) {
      description = "Opening scene"
    } else if (position < 0.4) {
      description = "Early content"
    } else if (position < 0.6) {
      description = "Main content"
    } else if (position < 0.8) {
      description = "Later content"
    } else {
      description = "Closing scene"
    }

    // Add context based on prompt
    if (isAction) {
      if (position < 0.3) {
        description += " with potential movement or action"
      } else if (position < 0.7) {
        description += " featuring main action sequence"
      } else {
        description += " with concluding action"
      }
    } else if (isEmotion) {
      if (position < 0.3) {
        description += " showing initial reactions"
      } else if (position < 0.7) {
        description += " with emotional expressions"
      } else {
        description += " displaying final emotions"
      }
    } else if (isComedy) {
      if (position < 0.3) {
        description += " with setup for comedy"
      } else if (position < 0.7) {
        description += " featuring comedic moments"
      } else {
        description += " with comedic conclusion"
      }
    } else if (isHighlight) {
      if (position < 0.3) {
        description += " from the beginning highlights"
      } else if (position < 0.7) {
        description += " from the main highlights"
      } else {
        description += " from the ending highlights"
      }
    }

    // Add timing context
    description += ` (${Math.floor(startTime)}s-${Math.floor(endTime)}s)`

    return description
  }

  createBasicAnalysis(videoDuration, prompt) {
    console.log("üìã Creating basic content analysis...")

    const segments = []
    const segmentCount = Math.min(6, Math.max(3, Math.floor(videoDuration / 3)))
    const segmentDuration = videoDuration / segmentCount

    for (let i = 0; i < segmentCount; i++) {
      const startTime = i * segmentDuration
      const endTime = Math.min((i + 1) * segmentDuration, videoDuration)

      segments.push({
        start: startTime,
        end: endTime,
        text: this.generateSegmentDescription(startTime, endTime, videoDuration, prompt),
      })
    }

    return {
      text: segments.map((seg) => seg.text).join(" "),
      segments: segments,
    }
  }

  cleanupFrames(frameDir) {
    try {
      if (fs.existsSync(frameDir)) {
        const files = fs.readdirSync(frameDir)
        for (const file of files) {
          fs.unlinkSync(path.join(frameDir, file))
        }
        fs.rmdirSync(frameDir)
        console.log("üóëÔ∏è Cleaned up extracted frames")
      }
    } catch (error) {
      console.error("‚ùå Failed to cleanup frames:", error)
    }
  }

  // Detect scene changes in video
  async detectSceneChanges(videoPath, videoDuration) {
    try {
      console.log("üé¨ Detecting scene changes...")

      const outputFile = path.join(this.tempDir, `scenes_${Date.now()}.txt`)

      // Use FFmpeg scene detection
      const command = `"${this.ffmpegPath}" -i "${videoPath}" -vf "select='gt(scene,0.3)',showinfo" -f null - 2>&1 | findstr "pts_time" > "${outputFile}"`

      await execAsync(command, { timeout: 30000 })

      const sceneChanges = []
      if (fs.existsSync(outputFile)) {
        const content = fs.readFileSync(outputFile, "utf8")
        const lines = content.split("\n").filter((line) => line.includes("pts_time"))

        for (const line of lines) {
          const match = line.match(/pts_time:(\d+\.?\d*)/)
          if (match) {
            sceneChanges.push(Number.parseFloat(match[1]))
          }
        }

        fs.unlinkSync(outputFile)
      }

      console.log(`‚úÖ Detected ${sceneChanges.length} scene changes`)
      return sceneChanges
    } catch (error) {
      console.error("‚ùå Scene detection failed:", error)
      return []
    }
  }
}

export default new VideoAnalysisService()
